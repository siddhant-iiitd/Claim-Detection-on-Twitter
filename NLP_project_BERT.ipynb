{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "TQXhWsh6t96p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MuAOZjcTGsf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install nlpaug"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ntxXnWR6uEJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random\n",
        "import re\n",
        "\n",
        "import nlpaug \n",
        "import nlpaug.augmenter.word as naw\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n"
      ],
      "metadata": {
        "id": "mSzbjjnMTNFR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NPA30l2h-V2",
        "outputId": "ef4f8118-1c18-4e55-e58b-65b3c26a2f5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih9s8ledhJiE",
        "outputId": "aa82a6a4-def2-43f5-a61b-2e1e0fa853a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9hNjIsSTRc9",
        "outputId": "cd497bd7-d24b-4886-a767-01033e5905e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data read"
      ],
      "metadata": {
        "id": "Z2qSVYFcuRnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the database\n",
        "url_train = \"/content/drive/MyDrive/F1_Claim_Detection_train.csv\"\n",
        "# url_train = \"/content/drive/MyDrive/augmented.csv\"\n",
        "df_train = pd.read_csv(url_train)\n",
        "\n",
        "url_test = \"/content/drive/MyDrive/F1_Claim_Detection_test.csv\"\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "metadata": {
        "id": "6NSgOWDOTUb_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation"
      ],
      "metadata": {
        "id": "qn7MDTBkuWbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug = naw.SynonymAug(aug_src='wordnet',aug_max=1)\n",
        "id = 6985\n",
        "for i in range(len(df_train)):\n",
        "  if(df_train[\"label\"].iloc[i] == 0):\n",
        "    # id += 1\n",
        "    # tweet_augmented_1 = aug.augment(df_train[\"tweet\"].iloc[i],n=1)\n",
        "    # df2 = {'tweet': tweet_augmented_1[0], 'label': 0, 'id':id}\n",
        "    # df_train = df_train.append(df2, ignore_index = True)\n",
        "    id += 1\n",
        "    tweet_augmented_2 = aug.augment(df_train[\"tweet\"].iloc[i],n=1)\n",
        "    df2 = {'tweet': tweet_augmented_2[0], 'label': 0, 'id':id}\n",
        "    df_train = df_train.append(df2, ignore_index = True)"
      ],
      "metadata": {
        "id": "shIlngJT07ru"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "m5CCD6Phu03r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing the data\n",
        "\n",
        "def preprocess(text):\n",
        "  text = re.sub(r\"@\\w+\\b\", \" \", text)\n",
        "  text = re.sub(r\"https?:\\/\\/\\w*|\\w+\\.com\\w*\", \" \", text)\n",
        "  text = re.sub(\"<\\w*>\", \" \", text)\n",
        "  text = re.sub(r\"\\\\n\", \" \", text)\n",
        "  text = re.sub(\"\\s+\", \" \", text)\n",
        "  return text\n",
        "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: preprocess(x))\n",
        "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "lC5xRoQdYEF_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "apka_EgPU_BA",
        "outputId": "14014430-d304-4b46-b838-89f07145857f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  label  id\n",
              "0  rt phin coffe club cure protect coronaviru the...      1   0\n",
              "1  look like corona viru antiblack iâm okay co cm...      0   1\n",
              "2  gonna monitor possit ncov viru know gonna say ...      1   2\n",
              "3  safe distanc cure covid19 part stay away face ...      1   3\n",
              "4  dose mimosa champagn cocain help get right cov...      0   4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b67e4bfe-9e5a-4694-b332-1cc0cac8569f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rt phin coffe club cure protect coronaviru the...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>look like corona viru antiblack iâm okay co cm...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gonna monitor possit ncov viru know gonna say ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>safe distanc cure covid19 part stay away face ...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dose mimosa champagn cocain help get right cov...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67e4bfe-9e5a-4694-b332-1cc0cac8569f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b67e4bfe-9e5a-4694-b332-1cc0cac8569f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b67e4bfe-9e5a-4694-b332-1cc0cac8569f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "0EtBT4E3u-MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert Tokenizer"
      ],
      "metadata": {
        "id": "j_GEtdRFvAVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
      ],
      "metadata": {
        "id": "r1XLSFuOT84K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_train = df_train[\"tweet\"]\n",
        "text_test = df_test[\"tweet\"]"
      ],
      "metadata": {
        "id": "zkBomNIHUz7T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = []\n",
        "attention_masking = []\n",
        "\n",
        "# encoding\n",
        "for sent in text_train:\n",
        "  ed = tokenizer.encode_plus(sent, add_special_tokens = True, max_length = 150, pad_to_max_length = True, return_attention_mask = True, return_tensors = 'pt')\n",
        "  token_ids.append(ed[\"input_ids\"])\n",
        "  attention_masking.append(ed[\"attention_mask\"])\n",
        "\n",
        "token_ids = torch.cat(token_ids, dim = 0)\n",
        "attention_masking = torch.cat(attention_masking, dim = 0)\n",
        "labels = torch.tensor(df_train[\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4jsiWFKVenh",
        "outputId": "b7ee8ab7-7f2f-4dbc-d0bf-92432b326eb1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting hyperparameters"
      ],
      "metadata": {
        "id": "hcZwTd96wKHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "# train_idc, test_idc = train_test_split(np.arange(len(labels)), test_size = 0.2, shuffle = True, stratify = labels)\n",
        "train_set = TensorDataset(token_ids[np.arange(len(labels))], attention_masking[np.arange(len(labels))], labels[np.arange(len(labels))])\n",
        "\n",
        "# test_set = TensorDataset(token_ids[test_idc], attention_masking[test_idc], labels[test_idc])\n",
        "\n",
        "train_dataloader = DataLoader(train_set, sampler = RandomSampler(train_set), batch_size = batch_size)\n",
        "\n",
        "# test_dataloader = DataLoader(test_set, sampler = SequentialSampler(test_set), batch_size = batch_size)"
      ],
      "metadata": {
        "id": "i_EH-EnJWzyc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2, output_attentions = False, output_hidden_states = False,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0xysjsUX5Me",
        "outputId": "462be439-3d3f-49a7-9219-66e9529b3693"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, eps = 1e-08)\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "POyQx3sFYNlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "epochs = 3"
      ],
      "metadata": {
        "id": "UC4ElKiSYhjm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics"
      ],
      "metadata": {
        "id": "F0TqiRRMvNKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "metadata": {
        "id": "yAriQWCAZCCi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "rWnNV8n5vUSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids,\n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    # model.eval()\n",
        "\n",
        "    # # Tracking variables \n",
        "    # val_accuracy = []\n",
        "    # val_precision = []\n",
        "    # val_recall = []\n",
        "    # val_specificity = []\n",
        "\n",
        "    # for batch in test_dataloader:\n",
        "    #     batch = tuple(t.to(device) for t in batch)\n",
        "    #     b_input_ids, b_input_mask, b_labels = batch\n",
        "    #     with torch.no_grad():\n",
        "    #       # Forward pass\n",
        "    #       eval_output = model(b_input_ids, \n",
        "    #                           token_type_ids = None,\n",
        "    #                           attention_mask = b_input_mask)\n",
        "    #     logits = eval_output.logits.detach().cpu().numpy()\n",
        "    #     label_ids = b_labels.to('cpu').numpy()\n",
        "    #     # Calculate validation metrics\n",
        "    #     b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "    #     val_accuracy.append(b_accuracy)\n",
        "    #     # Update precision only when (tp + fp) !=0; ignore nan\n",
        "    #     if b_precision != 'nan': val_precision.append(b_precision)\n",
        "    #     # Update recall only when (tp + fn) !=0; ignore nan\n",
        "    #     if b_recall != 'nan': val_recall.append(b_recall)\n",
        "    #     # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "    #     if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    # print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    # print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    # print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    # print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TukUxSgYjj4",
        "outputId": "970c0b36-cccc-4245-fc2d-2dbeb5c396e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  33%|███▎      | 1/3 [02:38<05:17, 158.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.3892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [05:15<02:37, 157.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.3292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 3/3 [07:52<00:00, 157.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t - Train loss: 0.2683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions"
      ],
      "metadata": {
        "id": "y0HrKZyyvXmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getPred(sent):\n",
        "\n",
        "\n",
        "  # We need Token IDs and Attention Mask for inference on the new sentence\n",
        "  test_ids = []\n",
        "  test_attention_mask = []\n",
        "\n",
        "  # Apply the tokenizer\n",
        "  encoding = tokenizer.encode_plus(sent, add_special_tokens = True, max_length = 150, pad_to_max_length = True, return_attention_mask = True, return_tensors = 'pt')\n",
        "\n",
        "  # Extract IDs and Attention Mask\n",
        "  test_ids.append(encoding['input_ids'])\n",
        "  test_attention_mask.append(encoding['attention_mask'])\n",
        "  test_ids = torch.cat(test_ids, dim = 0)\n",
        "  test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
        "\n",
        "  # Forward pass, calculate logit predictions\n",
        "  with torch.no_grad():\n",
        "    output = model(test_ids.to(device), attention_mask = test_attention_mask.to(device))\n",
        "\n",
        "  return np.argmax(output.logits.cpu().numpy()).flatten().item()\n"
      ],
      "metadata": {
        "id": "wohFSzeacZDZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for sent in df_test[\"tweet\"]:\n",
        "  preds.append(getPred(sent))"
      ],
      "metadata": {
        "id": "sLnWsQqVdDvm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds.count(0))"
      ],
      "metadata": {
        "id": "688paAogeJZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4cc1ac-6749-4cdf-f258-8c0f76513976"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating output on test set"
      ],
      "metadata": {
        "id": "Dz_n_PpqvdFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_out = pd.DataFrame()\n",
        "df_out[\"label\"] =  preds\n",
        "\n",
        "df_out['id'] = df_out.index"
      ],
      "metadata": {
        "id": "cozpTZnFgtij"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out.to_csv('output.csv')"
      ],
      "metadata": {
        "id": "ojC91gDmhHuW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference"
      ],
      "metadata": {
        "id": "26yO3BqLv5B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The blog followed was https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894"
      ],
      "metadata": {
        "id": "DKG3roRWjLZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}