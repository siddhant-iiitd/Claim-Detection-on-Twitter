{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS05Dl4p21WD"
      },
      "outputs": [],
      "source": [
        "pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "lL4AJzX4gtxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "from sentence_transformers import SentenceTransformer, losses, models, util\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "from sentence_transformers.readers import InputExample\n",
        "\n",
        "import torch \n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "import re"
      ],
      "metadata": {
        "id": "oOmKlaEm4LaF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFpzGADu5GZy",
        "outputId": "de0e9d99-b1d3-4ca4-919d-45cb2599d6e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Read"
      ],
      "metadata": {
        "id": "DXSSdEVdgyHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the database\n",
        "url_train = \"/content/drive/MyDrive/F1_Claim_Detection_train.csv\"\n",
        "df_train = pd.read_csv(url_train)\n",
        "\n",
        "url_test = \"/content/drive/MyDrive/F1_Claim_Detection_test.csv\"\n",
        "df_test = pd.read_csv(url_test)"
      ],
      "metadata": {
        "id": "1Y0d7MQm5pBq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "\n",
        "def preprocess(text):\n",
        "  text = re.sub(r\"@\\w+\\b\", \" \", text)\n",
        "  text = re.sub(r\"https?:\\/\\/\\w*|\\w+\\.com\\w*\", \" \", text)\n",
        "  text = re.sub(\"<\\w*>\", \" \", text)\n",
        "  text = re.sub(r\"\\\\n\", \" \", text)\n",
        "  text = re.sub(\"\\s+\", \" \", text)\n",
        "  return text\n",
        "df_train[\"tweet\"] = df_train[\"tweet\"].apply(lambda x: preprocess(x))\n",
        "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "6FZmACr5XcJu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "9eJ6XWNAg0eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the embeddings\n",
        "\n",
        "def get_feature_model(data_frame):\n",
        "  non_cont_model2 = SentenceTransformer('sentence-transformers/all-distilroberta-v1')\n",
        "  feature1 = non_cont_model2.encode(data_frame[\"tweet\"])\n",
        "  return feature1\n",
        "    \n",
        "\n",
        "\n",
        "feature_1_train = get_feature_model(df_train)"
      ],
      "metadata": {
        "id": "Klm3XJye4bYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the train-test split and initializing the classifiers\n",
        "X_train, Y_train = np.array(feature_1_train), df_train[\"label\"]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(np.array(feature_1_train), df_train[\"label\"], test_size = 0.2)\n",
        "clf_svc = SVC(gamma='auto')\n",
        "clf_lr = LogisticRegression(random_state=0)\n",
        "clf_mlp = MLPClassifier(random_state=1, max_iter=1000, early_stopping = True)\n",
        "clf_adaboost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 2), n_estimators=100, random_state=0)\n",
        "# clf = make_pipeline(LogisticRegression(random_state=0))\n",
        "\n",
        "# Training all the models\n",
        "clf_svc.fit(X_train, Y_train)\n",
        "clf_lr.fit(X_train, Y_train)\n",
        "clf_mlp.fit(X_train, Y_train)\n",
        "clf_adaboost.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "N2K0xMDS9Lc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "pred_test_lr = clf_lr.predict(X_test)\n",
        "pred_train_lr = clf_lr.predict(X_train)\n",
        "\n",
        "pred_test_mlp = clf_mlp.predict(X_test)\n",
        "pred_train_mlp = clf_mlp.predict(X_train)\n",
        "\n",
        "pred_test_svc = clf_svc.predict(X_test)\n",
        "pred_train_svc = clf_svc.predict(X_train)\n",
        "\n",
        "pred_test_adaboost = clf_adaboost.predict(X_test)\n",
        "pred_train_adaboost = clf_adaboost.predict(X_train)"
      ],
      "metadata": {
        "id": "cRL0hPtromgL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_1_test = get_feature_model2(df_test)\n",
        "\n",
        "# X_test, Y_test = np.array(feature_1_test), df_test[\"label\"]"
      ],
      "metadata": {
        "id": "-pg095Cq-jIf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "gfYmyqMNnm4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============================================================================\")\n",
        "print(\"TRAINING\")\n",
        "print(accuracy_score(pred_train_lr, Y_train))\n",
        "\n",
        "print(\"==============================================================================\")\n",
        "print(\"TESTING\")\n",
        "print(accuracy_score(pred_test_lr, Y_test))\n",
        "\n",
        "\n",
        "# print(\"==============================================================================\")\n",
        "# print(\"TRAINING\")\n",
        "# # pred_train = clf.predict(X_train)\n",
        "# print(classification_report(pred_train, Y_train))\n",
        "print(\"==============================================================================\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"TESTING\")\n",
        "# pred_test = clf.predict(X_test)\n",
        "print(classification_report(pred_test_lr, Y_test))\n",
        "\n",
        "print(\"==============================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u36vlLbH-WF3",
        "outputId": "4b87eeee-60d5-4d22-8440-e7d44d2c1d75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================\n",
            "TRAINING\n",
            "0.889226914817466\n",
            "==============================================================================\n",
            "TESTING\n",
            "0.8683834048640916\n",
            "==============================================================================\n",
            "CLASSIFICATION REPORT\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.88      0.14        17\n",
            "           1       1.00      0.87      0.93      1381\n",
            "\n",
            "    accuracy                           0.87      1398\n",
            "   macro avg       0.54      0.88      0.53      1398\n",
            "weighted avg       0.99      0.87      0.92      1398\n",
            "\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVC"
      ],
      "metadata": {
        "id": "vhk9vQigpYoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============================================================================\")\n",
        "print(\"TRAINING\")\n",
        "print(accuracy_score(pred_train_svc, Y_train))\n",
        "\n",
        "print(\"==============================================================================\")\n",
        "print(\"TESTING\")\n",
        "print(accuracy_score(pred_test_svc, Y_test))\n",
        "\n",
        "\n",
        "# print(\"==============================================================================\")\n",
        "# print(\"TRAINING\")\n",
        "# # pred_train = clf.predict(X_train)\n",
        "# print(classification_report(pred_train, Y_train))\n",
        "print(\"==============================================================================\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"TESTING\")\n",
        "# pred_test = clf.predict(X_test)\n",
        "print(classification_report(pred_test_svc, Y_test))\n",
        "\n",
        "print(\"==============================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ppHPNsygbDE",
        "outputId": "dce4649a-ece0-4503-dfb1-3dcfc2c82c02"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================\n",
            "TRAINING\n",
            "0.8775948460987831\n",
            "==============================================================================\n",
            "TESTING\n",
            "0.8590844062947067\n",
            "==============================================================================\n",
            "CLASSIFICATION REPORT\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.86      0.92      1398\n",
            "\n",
            "    accuracy                           0.86      1398\n",
            "   macro avg       0.50      0.43      0.46      1398\n",
            "weighted avg       1.00      0.86      0.92      1398\n",
            "\n",
            "==============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "pqI5px9IpZst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============================================================================\")\n",
        "print(\"TRAINING\")\n",
        "print(accuracy_score(pred_train_mlp, Y_train))\n",
        "\n",
        "print(\"==============================================================================\")\n",
        "print(\"TESTING\")\n",
        "print(accuracy_score(pred_test_mlp, Y_test))\n",
        "\n",
        "\n",
        "# print(\"==============================================================================\")\n",
        "# print(\"TRAINING\")\n",
        "# # pred_train = clf.predict(X_train)\n",
        "# print(classification_report(pred_train, Y_train))\n",
        "print(\"==============================================================================\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"TESTING\")\n",
        "# pred_test = clf.predict(X_test)\n",
        "print(classification_report(pred_test_mlp, Y_test))\n",
        "\n",
        "print(\"==============================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHamyu7SpCWJ",
        "outputId": "7562523a-f665-45d8-c10e-830dca62ef6b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================\n",
            "TRAINING\n",
            "0.8920901932712957\n",
            "==============================================================================\n",
            "TESTING\n",
            "0.8683834048640916\n",
            "==============================================================================\n",
            "CLASSIFICATION REPORT\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      0.76      0.17        25\n",
            "           1       1.00      0.87      0.93      1373\n",
            "\n",
            "    accuracy                           0.87      1398\n",
            "   macro avg       0.55      0.82      0.55      1398\n",
            "weighted avg       0.98      0.87      0.91      1398\n",
            "\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaboost"
      ],
      "metadata": {
        "id": "myYC8w_-pg5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==============================================================================\")\n",
        "print(\"TRAINING\")\n",
        "print(accuracy_score(pred_train_adaboost, Y_train))\n",
        "\n",
        "print(\"==============================================================================\")\n",
        "print(\"TESTING\")\n",
        "print(accuracy_score(pred_test_adaboost, Y_test))\n",
        "\n",
        "\n",
        "# print(\"==============================================================================\")\n",
        "# print(\"TRAINING\")\n",
        "# # pred_train = clf.predict(X_train)\n",
        "# print(classification_report(pred_train, Y_train))\n",
        "print(\"==============================================================================\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"TESTING\")\n",
        "# pred_test = clf.predict(X_test)\n",
        "print(classification_report(pred_test_adaboost, Y_test))\n",
        "\n",
        "print(\"==============================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzT3zRsDpUMo",
        "outputId": "d6742efb-1382-4727-c08e-e344869e81e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================\n",
            "TRAINING\n",
            "0.98067287043665\n",
            "==============================================================================\n",
            "TESTING\n",
            "0.8404864091559371\n",
            "==============================================================================\n",
            "CLASSIFICATION REPORT\n",
            "TESTING\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.40      0.31       124\n",
            "           1       0.94      0.88      0.91      1274\n",
            "\n",
            "    accuracy                           0.84      1398\n",
            "   macro avg       0.59      0.64      0.61      1398\n",
            "weighted avg       0.88      0.84      0.86      1398\n",
            "\n",
            "==============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Output"
      ],
      "metadata": {
        "id": "nLyNw5SOh5Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_1_test = get_feature_model(df_test)\n",
        "\n",
        "X_test= np.array(feature_1_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "VgL-Jg91h43W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = clf.predict(X_test)\n",
        "df_out = pd.DataFrame()\n",
        "df_out[\"label\"] =  pred_y\n",
        "\n",
        "df_out['id'] = df_out.index"
      ],
      "metadata": {
        "id": "g0wzUFiru8NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_out.to_csv('output.csv')"
      ],
      "metadata": {
        "id": "UU86F0Gkjk24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}